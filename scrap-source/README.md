# An√°lisis Electoral: Scraping y Transcripci√≥n

Herramientas para descargar audio/video de publicaciones en redes sociales y transcribir el contenido usando IA.

## Caracter√≠sticas

- üé¨ Descarga de audio/video desde Facebook, TikTok y YouTube
- üéôÔ∏è Transcripci√≥n autom√°tica con Whisper
- üí¨ Scraping de comentarios de posts p√∫blicos en Facebook
- üìä Procesamiento batch de m√∫ltiples URLs
- ‚òÅÔ∏è **Appwrite Function** para transcripci√≥n y scraping serverless con almacenamiento en bucket

## Requisitos

- Python 3.11+
- ffmpeg (Linux: `sudo apt install ffmpeg`)
- Paquetes Python:
  ```bash
  pip install -r requirements.txt
  ```
- Playwright (solo si usas `scraper-fb.py`):
  ```bash
  python -m playwright install chromium
  ```

## Instalaci√≥n r√°pida

```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/analisis-electoral.git
cd analisis-electoral

# Crear entorno virtual
python3.11 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

## Uso

### Transcripci√≥n de una sola URL (local)

```bash
python src/transcriptor.py --url "https://www.youtube.com/watch?v=dQw4w9WgXcQ" --outdir datos-crudos
```

---

## üöÄ Appwrite Function (Transcriptor + Scraper)

El archivo `src/main.py` es una funci√≥n de Appwrite que permite:
1. **Transcribir videos** de Facebook, TikTok, YouTube
2. **Scrapear comentarios** de posts de Facebook

### Configuraci√≥n en Appwrite

1. **Crear un proyecto** en [Appwrite Console](https://cloud.appwrite.io/console)

2. **Crear un bucket** para almacenar los resultados:
   - Ve a Storage ‚Üí Create Bucket
   - Anota el `BUCKET_ID`

3. **Crear una API Key** con permisos:
   - `storage.files.read`
   - `storage.files.write`

4. **Crear la funci√≥n**:
   - Ve a Functions ‚Üí Create Function
   - Selecciona **Python 3.11** como runtime ‚ö†Ô∏è (obligatorio)
   - Configura las variables de entorno:

   | Variable | Descripci√≥n |
   |----------|-------------|
   | `APPWRITE_ENDPOINT` | `https://cloud.appwrite.io/v1` o tu endpoint |
   | `APPWRITE_PROJECT_ID` | ID de tu proyecto |
   | `APPWRITE_API_KEY` | API Key con permisos de storage |
   | `APPWRITE_BUCKET_ID` | ID del bucket de resultados |
   | `WHISPER_MODEL_SIZE` | `tiny`, `base`, `small`, `medium`, `large` (default: `small`) |
   | `FACEBOOK_COOKIES_BASE64` | Cookies de Facebook en base64 (opcional) |

5. **Desplegar el c√≥digo**:
   - Conecta tu repositorio Git o sube manualmente los archivos

### Uso de la funci√≥n

**GET** - Informaci√≥n de la funci√≥n:
```bash
curl https://[FUNCTION_URL]
```

#### Transcribir un video:
```bash
curl -X POST https://[FUNCTION_URL] \
  -H "Content-Type: application/json" \
  -d '{
    "action": "transcribe",
    "url": "https://www.youtube.com/watch?v=VIDEO_ID",
    "filename": "mi-transcripcion"
  }'
```

#### Scrapear comentarios de Facebook:
```bash
# Generar cookies en base64
COOKIES_B64=$(cat facebook-cookies.json | base64 -w 0)

# Ejecutar scraping
curl -X POST https://[FUNCTION_URL] \
  -H "Content-Type: application/json" \
  -d '{
    "action": "scrape",
    "url": "https://www.facebook.com/user/posts/123456",
    "cookies_base64": "'"$COOKIES_B64"'",
    "max_clicks": 30
  }'
```

### Respuestas

**Transcripci√≥n exitosa:**
```json
{
  "ok": true,
  "message": "Transcripci√≥n completada",
  "file_id": "abc123xyz",
  "filename": "transcripcion_20260130.json",
  "idioma": "es",
  "texto_preview": "Texto de los primeros 500 caracteres..."
}
```

**Scraping exitoso:**
```json
{
  "ok": true,
  "message": "Scraping completado",
  "file_id": "xyz789abc",
  "filename": "comments_20260130.json",
  "total_comentarios": 150,
  "preview": [{"author": "Usuario1", "text": "Comentario..."}]
}
```

### Formato de archivos guardados

**Transcripci√≥n:**
```json
{
  "url_origen": "https://...",
  "fecha_transcripcion": "2026-01-30T10:30:00",
  "idioma": "es",
  "probabilidad_idioma": 0.98,
  "texto_completo": "Transcripci√≥n completa aqu√≠...",
  "segmentos": [
    {"start": 0.0, "end": 2.5, "text": "Primer segmento"}
  ]
}
```

**Comentarios:**
```json
{
  "url_origen": "https://...",
  "fecha_scraping": "2026-01-30T10:30:00",
  "total_comentarios": 150,
  "comentarios": [
    {"author": "Usuario1", "text": "Comentario del usuario..."}
  ]
}
```

---

### Batch de m√∫ltiples URLs


```bash
# Crear archivo urls.txt con una URL por l√≠nea
echo "https://www.youtube.com/watch?v=..." >> urls.txt
echo "https://www.tiktok.com/..." >> urls.txt

# Ejecutar
python runner.py --list urls.txt --outdir datos-crudos
```

### Scraper de Facebook (posts p√∫blicos)

```bash
python scraper-fb.py --url "URL_DEL_POST_PUBLICO" --cookies facebook-cookies.json --headless
```

#### Configurar cookies de Facebook

1. Instala la extensi√≥n [Cookie-Editor](https://chromewebstore.google.com/detail/cookie-editor/hlkennddhgpbpiagedomjjfgnpmgfen) en Chrome/Chromium
2. Ve a facebook.com e inicia sesi√≥n
3. Abre Cookie-Editor ‚Üí Selecciona el √≠cono de exportar (export) 
4. Copia el JSON exportado
5. Crea `facebook-cookies.json` en la ra√≠z del proyecto y pega el contenido

**Ejemplo de estructura**: Ver [facebook-cookies.example.json](facebook-cookies.example.json)

‚ö†Ô∏è **IMPORTANTE**: El archivo `facebook-cookies.json` est√° en `.gitignore` para proteger tus credenciales. Nunca lo subas a GitHub.

### Scraping de comentarios de Facebook

```bash
python scraper-fb-comments.py --url "URL_DEL_POST_PUBLICO" --cookies facebook-cookies.json --outdir datos-crudos --max-clicks 30
```

## Consideraciones importantes

### Privacidad y Cumplimiento Legal

- ‚ö†Ô∏è Usa solo contenido **p√∫blico** y con prop√≥sitos de investigaci√≥n
- üìã Respeta [GDPR](https://gdpr-info.eu/), CCPA y leyes de protecci√≥n de datos locales
- üîí Anonimiza datos personales antes de compartir resultados
- üìñ Revisar pol√≠ticas de cada plataforma (Facebook, TikTok, YouTube)

### Consejos t√©cnicos

- Muchas URLs requieren sesi√≥n/cookies. Si falla descarga: usa navegador con sesi√≥n activa
- Agrega pausas entre solicitudes para no saturar servidores
- Usa user-agents realistas y respeta `robots.txt`

## Carpeta de salida

- Los archivos de transcripci√≥n se guardan en `datos-crudos/` con nombre `transcripcion_YYYYMMDD-HHMMSS.txt`.
